{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bbea4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 20\n"
     ]
    }
   ],
   "source": [
    "import mrcnn\n",
    "import mrcnn.config\n",
    "import mrcnn.model\n",
    "import mrcnn.visualize\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['BG', 'drone']\n",
    "\n",
    "class SimpleConfig(mrcnn.config.Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"coco_inference\"\n",
    "\n",
    "    # Set the number of GPUs to use along with the number of images per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes = number of classes + 1 (+1 for the background).\n",
    "    NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Initialize the Mask R-CNN model for inference and then load the weights.\n",
    "model = mrcnn.model.MaskRCNN(mode=\"inference\",\n",
    "                             config=SimpleConfig(),\n",
    "                             model_dir=os.getcwd())\n",
    "\n",
    "# Load the weights into the model.\n",
    "model.load_weights(filepath=\"logs\\drone_detection20241123T1349\\mask_rcnn_drone_detection_0020.h5\", by_name=True)\n",
    "\n",
    "# Directory for validation images\n",
    "validation_dir = \"dataset/validation\"\n",
    "image_files = [f for f in os.listdir(validation_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Choose a random image file from the list\n",
    "random_image_file = random.choice(image_files)\n",
    "\n",
    "# Load the input image, convert it from BGR to RGB channel\n",
    "image = cv2.imread(os.path.join(validation_dir, random_image_file))\n",
    "\n",
    "# Resize the image while maintaining aspect ratio\n",
    "height, width = image.shape[:2]\n",
    "scale = 1024 / max(height, width)\n",
    "resized_image = cv2.resize(image, (int(width * scale), int(height * scale)))\n",
    "\n",
    "# Pad the image to 1024x1024 if needed\n",
    "padded_image = np.zeros((1024, 1024, 3), dtype=np.uint8)\n",
    "padded_image[:resized_image.shape[0], :resized_image.shape[1]] = resized_image\n",
    "\n",
    "# Check if the image was loaded properly\n",
    "if padded_image is None:\n",
    "    print(\"Error: Unable to load image. Check the file path.\")\n",
    "else:\n",
    "    padded_image = cv2.cvtColor(padded_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform a forward pass of the network to obtain the results\n",
    "r = model.detect([padded_image])[0]\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.4  # Adjusted threshold\n",
    "MIN_BOX_AREA = 100  # Minimum box area\n",
    "\n",
    "# Filter indices of detections with scores higher than the threshold\n",
    "high_confidence_indices = [i for i, score in enumerate(r['scores']) if score > CONFIDENCE_THRESHOLD]\n",
    "\n",
    "# Loop through detections and filter based on confidence and bounding box size\n",
    "for i in range(len(r['scores'])):\n",
    "    y1, x1, y2, x2 = r['rois'][i]\n",
    "    box_height = y2 - y1\n",
    "    box_width = x2 - x1\n",
    "    box_area = box_height * box_width\n",
    "    \n",
    "    if r['scores'][i] > CONFIDENCE_THRESHOLD and box_area > MIN_BOX_AREA:\n",
    "        print(f\"Object {i + 1}:\")\n",
    "        print(f\"  Class: {CLASS_NAMES[r['class_ids'][i]]}\")\n",
    "        print(f\"  Bounding box: {r['rois'][i]}\")  # y1, x1, y2, x2\n",
    "        print(f\"  Confidence score: {r['scores'][i]}\")\n",
    "        # Break after the first detected drone\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Filtered out Object {i + 1} with tiny bounding box or low confidence.\")\n",
    "\n",
    "# Visualize only the high-confidence detections\n",
    "if len(high_confidence_indices) > 0:\n",
    "    mrcnn.visualize.display_instances(image=padded_image,  # Use padded_image for visualization\n",
    "                                      boxes=r['rois'][high_confidence_indices],\n",
    "                                      masks=r['masks'][:, :, high_confidence_indices],\n",
    "                                      class_ids=r['class_ids'][high_confidence_indices],\n",
    "                                      class_names=CLASS_NAMES,\n",
    "                                      scores=r['scores'][high_confidence_indices])\n",
    "else:\n",
    "    print(\"No high-confidence detections found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0977a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d498c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
